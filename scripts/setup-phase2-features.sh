#!/bin/bash

# é‡åŒ–äº¤æ˜“ç³»ç»Ÿç¬¬äºŒé˜¶æ®µå®‰è£…è„šæœ¬
# ç‰¹å¾å·¥ç¨‹æ¨¡å—å®‰è£…å’Œé…ç½®

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µæ˜¯å¦å®Œæˆ
check_phase1_completion() {
    log_info "æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µå®ŒæˆçŠ¶æ€..."
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    local required_files=(
        "src/services/dataSource/DataSourceManager.ts"
        "server/app/service/clickhouse.js"
        "src/services/realtimeDataService.ts"
    )
    
    for file in "${required_files[@]}"; do
        if [ ! -f "$file" ]; then
            log_error "ç¬¬ä¸€é˜¶æ®µæ–‡ä»¶ $file ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆç¬¬ä¸€é˜¶æ®µå®‰è£…"
            exit 1
        fi
    done
    
    log_success "ç¬¬ä¸€é˜¶æ®µæ£€æŸ¥é€šè¿‡"
}

# å®‰è£…å‰ç«¯ä¾èµ–
install_frontend_dependencies() {
    log_info "å®‰è£…å‰ç«¯ç‰¹å¾å·¥ç¨‹ä¾èµ–..."
    
    # å®‰è£…æ•°å­¦è®¡ç®—åº“
    npm install mathjs
    npm install ml-matrix
    npm install simple-statistics
    
    # å®‰è£…å›¾è¡¨åº“
    npm install echarts
    npm install @types/echarts
    
    # å®‰è£…æ•°æ®å¤„ç†åº“
    npm install lodash
    npm install @types/lodash
    
    log_success "å‰ç«¯ä¾èµ–å®‰è£…å®Œæˆ"
}

# å®‰è£…åŽç«¯ä¾èµ–
install_backend_dependencies() {
    log_info "å®‰è£…åŽç«¯ç‰¹å¾å·¥ç¨‹ä¾èµ–..."
    
    cd server
    
    # å®‰è£…æ•°å­¦è®¡ç®—åº“
    npm install mathjs
    npm install ml-matrix
    npm install simple-statistics
    
    # å®‰è£…æ•°æ®å¤„ç†åº“
    npm install lodash
    npm install moment
    
    # å®‰è£…æœºå™¨å­¦ä¹ åº“
    npm install ml-regression
    npm install ml-kmeans
    
    cd ..
    
    log_success "åŽç«¯ä¾èµ–å®‰è£…å®Œæˆ"
}

# å®‰è£…Pythonç§‘å­¦è®¡ç®—åº“
install_python_libraries() {
    log_info "å®‰è£…Pythonç§‘å­¦è®¡ç®—åº“..."
    
    if command -v python3 &> /dev/null; then
        # æ›´æ–°requirements.txt
        cat >> server/scripts/requirements.txt << EOF

# ç¬¬äºŒé˜¶æ®µï¼šç‰¹å¾å·¥ç¨‹ä¾èµ–
scikit-learn>=1.3.0
scipy>=1.10.0
statsmodels>=0.14.0
ta-lib>=0.4.0
empyrical>=0.5.0
pyfolio>=0.9.0
zipline>=2.2.0
backtrader>=1.9.0
vectorbt>=0.25.0
alphalens>=0.4.0
EOF
        
        # å®‰è£…Pythonä¾èµ–
        pip3 install -r server/scripts/requirements.txt
        
        log_success "Pythonç§‘å­¦è®¡ç®—åº“å®‰è£…å®Œæˆ"
    else
        log_warning "Python3 æœªå®‰è£…ï¼Œè·³è¿‡Pythonåº“å®‰è£…"
    fi
}

# åˆ›å»ºå› å­æ•°æ®åº“è¡¨
create_factor_tables() {
    log_info "åˆ›å»ºå› å­æ•°æ®åº“è¡¨..."
    
    # æ£€æŸ¥MySQLè¿žæŽ¥
    if ! mysql -h127.0.0.1 -uroot -proot -e "SELECT 1;" > /dev/null 2>&1; then
        log_warning "æ— æ³•è¿žæŽ¥åˆ°MySQLæ•°æ®åº“ï¼Œè·³è¿‡è¡¨åˆ›å»º"
        return
    fi
    
    # åˆ›å»ºSQLè„šæœ¬
    cat > server/scripts/create_factor_tables.sql << EOF
-- å› å­æ•°æ®è¡¨
CREATE TABLE IF NOT EXISTS factor_data (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    factor_name VARCHAR(100) NOT NULL,
    factor_type ENUM('technical', 'fundamental', 'alternative') NOT NULL,
    factor_value DECIMAL(20,8),
    date DATE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_symbol_date (symbol, date),
    INDEX idx_factor_name (factor_name),
    INDEX idx_factor_type (factor_type),
    UNIQUE KEY uk_symbol_factor_date (symbol, factor_name, date)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- å› å­é…ç½®è¡¨
CREATE TABLE IF NOT EXISTS factor_configs (
    id INT AUTO_INCREMENT PRIMARY KEY,
    factor_name VARCHAR(100) NOT NULL UNIQUE,
    factor_type ENUM('technical', 'fundamental', 'alternative') NOT NULL,
    description TEXT,
    category VARCHAR(50),
    parameters JSON,
    enabled BOOLEAN DEFAULT TRUE,
    priority INT DEFAULT 0,
    cache_expiry INT DEFAULT 3600,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- å› å­è®¡ç®—ä»»åŠ¡è¡¨
CREATE TABLE IF NOT EXISTS factor_calculation_tasks (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    factor_configs JSON NOT NULL,
    status ENUM('pending', 'running', 'completed', 'failed') DEFAULT 'pending',
    progress INT DEFAULT 0,
    result JSON,
    error_message TEXT,
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_symbol_status (symbol, status),
    INDEX idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- å› å­ç›¸å…³æ€§çŸ©é˜µè¡¨
CREATE TABLE IF NOT EXISTS factor_correlations (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL,
    factor1_name VARCHAR(100) NOT NULL,
    factor2_name VARCHAR(100) NOT NULL,
    correlation DECIMAL(10,8) NOT NULL,
    date_range_start DATE NOT NULL,
    date_range_end DATE NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_symbol (symbol),
    INDEX idx_factors (factor1_name, factor2_name),
    UNIQUE KEY uk_symbol_factors_range (symbol, factor1_name, factor2_name, date_range_start, date_range_end)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- æ’å…¥é»˜è®¤å› å­é…ç½®
INSERT IGNORE INTO factor_configs (factor_name, factor_type, description, category, parameters, priority) VALUES
('sma_cross', 'technical', 'å‡çº¿äº¤å‰ä¿¡å·', 'è¶‹åŠ¿è·Ÿè¸ª', '{"shortPeriod": 5, "longPeriod": 20}', 1),
('rsi_divergence', 'technical', 'RSIèƒŒç¦»ä¿¡å·', 'åŠ¨é‡æŒ‡æ ‡', '{"period": 14, "lookback": 20}', 2),
('macd_signal', 'technical', 'MACDä¿¡å·å¼ºåº¦', 'åŠ¨é‡æŒ‡æ ‡', '{"fastPeriod": 12, "slowPeriod": 26, "signalPeriod": 9}', 3),
('bollinger_position', 'technical', 'å¸ƒæž—å¸¦ä½ç½®', 'æ³¢åŠ¨æ€§æŒ‡æ ‡', '{"period": 20, "multiplier": 2}', 4),
('volume_price_trend', 'technical', 'é‡ä»·è¶‹åŠ¿', 'é‡ä»·å…³ç³»', '{"period": 10}', 5),
('momentum', 'technical', 'åŠ¨é‡æŒ‡æ ‡', 'åŠ¨é‡æŒ‡æ ‡', '{"period": 10}', 6),
('volatility', 'technical', 'æ³¢åŠ¨çŽ‡', 'æ³¢åŠ¨æ€§æŒ‡æ ‡', '{"period": 20}', 7),
('trend_strength', 'technical', 'è¶‹åŠ¿å¼ºåº¦', 'è¶‹åŠ¿æŒ‡æ ‡', '{"period": 20}', 8),
('roe_trend', 'fundamental', 'ROEè¶‹åŠ¿', 'ç›ˆåˆ©èƒ½åŠ›', '{"lookback": 4}', 9),
('pe_relative', 'fundamental', 'ç›¸å¯¹PE', 'ä¼°å€¼æŒ‡æ ‡', '{}', 10),
('debt_ratio', 'fundamental', 'å€ºåŠ¡æ¯”çŽ‡', 'è´¢åŠ¡å¥åº·', '{}', 11),
('revenue_growth', 'fundamental', 'è¥æ”¶å¢žé•¿', 'æˆé•¿èƒ½åŠ›', '{"periods": 4}', 12),
('profit_margin', 'fundamental', 'åˆ©æ¶¦çŽ‡', 'ç›ˆåˆ©èƒ½åŠ›', '{}', 13),
('sentiment_score', 'alternative', 'å¸‚åœºæƒ…ç»ª', 'æƒ…ç»ªæŒ‡æ ‡', '{}', 14),
('money_flow', 'alternative', 'èµ„é‡‘æµå‘', 'èµ„é‡‘æµå‘', '{"period": 20}', 15),
('correlation_factor', 'alternative', 'å¸‚åœºå…³è”æ€§', 'å…³è”æ€§æŒ‡æ ‡', '{"period": 60, "benchmark": "000001"}', 16),
('volatility_regime', 'alternative', 'æ³¢åŠ¨çŽ‡çŠ¶æ€', 'æ³¢åŠ¨æ€§çŠ¶æ€', '{"shortPeriod": 10, "longPeriod": 60}', 17);
EOF
    
    # æ‰§è¡ŒSQLè„šæœ¬
    mysql -h127.0.0.1 -uroot -proot stock_analysis < server/scripts/create_factor_tables.sql
    
    log_success "å› å­æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ"
}

# é…ç½®ClickHouseå› å­è¡¨
setup_clickhouse_factor_tables() {
    log_info "é…ç½®ClickHouseå› å­è¡¨..."
    
    # æ£€æŸ¥ClickHouseè¿žæŽ¥
    if ! curl -s http://localhost:8123/ > /dev/null 2>&1; then
        log_warning "ClickHouse æœåŠ¡æœªè¿è¡Œï¼Œè·³è¿‡å› å­è¡¨åˆ›å»º"
        return
    fi
    
    # åˆ›å»ºClickHouseå› å­è¡¨
    cat > server/scripts/create_clickhouse_factor_tables.sql << EOF
-- å› å­æ•°æ®è¡¨
CREATE TABLE IF NOT EXISTS stock_data.factor_data (
    symbol String,
    factor_name String,
    factor_type Enum8('technical' = 1, 'fundamental' = 2, 'alternative' = 3),
    factor_value Float64,
    date Date,
    datetime DateTime,
    metadata String,
    data_source String,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (symbol, factor_name, date)
SETTINGS index_granularity = 8192;

-- å› å­ç›¸å…³æ€§è¡¨
CREATE TABLE IF NOT EXISTS stock_data.factor_correlations (
    symbol String,
    factor1_name String,
    factor2_name String,
    correlation Float64,
    date_range_start Date,
    date_range_end Date,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date_range_start)
ORDER BY (symbol, factor1_name, factor2_name, date_range_start)
SETTINGS index_granularity = 8192;

-- å› å­é‡è¦æ€§è¡¨
CREATE TABLE IF NOT EXISTS stock_data.factor_importance (
    symbol String,
    factor_name String,
    importance_score Float64,
    importance_rank UInt32,
    calculation_method String,
    date Date,
    created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (symbol, date, importance_rank)
SETTINGS index_granularity = 8192;
EOF
    
    # æ‰§è¡ŒClickHouse SQL
    curl -X POST 'http://localhost:8123/' --data-binary @server/scripts/create_clickhouse_factor_tables.sql
    
    log_success "ClickHouseå› å­è¡¨åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºå› å­è®¡ç®—Pythonè„šæœ¬
create_factor_calculation_scripts() {
    log_info "åˆ›å»ºå› å­è®¡ç®—Pythonè„šæœ¬..."
    
    # åˆ›å»ºPythonå› å­è®¡ç®—è„šæœ¬
    cat > server/scripts/factor_calculator.py << 'EOF'
#!/usr/bin/env python3
"""
å› å­è®¡ç®—è„šæœ¬
ä½¿ç”¨Pythonç§‘å­¦è®¡ç®—åº“è¿›è¡Œé«˜æ€§èƒ½å› å­è®¡ç®—
"""

import numpy as np
import pandas as pd
import talib
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

class FactorCalculator:
    def __init__(self):
        self.scaler = StandardScaler()
    
    def calculate_technical_factors(self, data):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å› å­"""
        factors = {}
        
        # ä»·æ ¼æ•°æ®
        high = np.array(data['high'])
        low = np.array(data['low'])
        close = np.array(data['close'])
        volume = np.array(data['volume'])
        
        # è¶‹åŠ¿å› å­
        factors['sma_5'] = talib.SMA(close, timeperiod=5)
        factors['sma_20'] = talib.SMA(close, timeperiod=20)
        factors['ema_12'] = talib.EMA(close, timeperiod=12)
        factors['ema_26'] = talib.EMA(close, timeperiod=26)
        
        # åŠ¨é‡å› å­
        factors['rsi'] = talib.RSI(close, timeperiod=14)
        factors['momentum'] = talib.MOM(close, timeperiod=10)
        factors['roc'] = talib.ROC(close, timeperiod=10)
        
        # MACDå› å­
        macd, macd_signal, macd_hist = talib.MACD(close)
        factors['macd'] = macd
        factors['macd_signal'] = macd_signal
        factors['macd_histogram'] = macd_hist
        
        # æ³¢åŠ¨çŽ‡å› å­
        factors['atr'] = talib.ATR(high, low, close, timeperiod=14)
        factors['volatility'] = pd.Series(close).rolling(20).std()
        
        # å¸ƒæž—å¸¦å› å­
        bb_upper, bb_middle, bb_lower = talib.BBANDS(close)
        factors['bb_upper'] = bb_upper
        factors['bb_lower'] = bb_lower
        factors['bb_position'] = (close - bb_lower) / (bb_upper - bb_lower)
        
        # æˆäº¤é‡å› å­
        factors['volume_sma'] = talib.SMA(volume, timeperiod=20)
        factors['volume_ratio'] = volume / factors['volume_sma']
        
        return factors
    
    def calculate_fundamental_factors(self, financial_data):
        """è®¡ç®—åŸºæœ¬é¢å› å­"""
        factors = {}
        
        if not financial_data:
            return factors
        
        df = pd.DataFrame(financial_data)
        
        # ç›ˆåˆ©èƒ½åŠ›å› å­
        factors['roe'] = df['roe']
        factors['roa'] = df['roa']
        factors['gross_margin'] = df['gross_margin']
        factors['net_margin'] = df['net_margin']
        
        # æˆé•¿æ€§å› å­
        factors['revenue_growth'] = df['revenue'].pct_change()
        factors['profit_growth'] = df['net_profit'].pct_change()
        
        # è´¢åŠ¡å¥åº·å› å­
        factors['debt_to_equity'] = df['debt_to_equity']
        factors['current_ratio'] = df['current_ratio']
        factors['quick_ratio'] = df['quick_ratio']
        
        # ä¼°å€¼å› å­
        factors['pe_ratio'] = df['pe_ratio']
        factors['pb_ratio'] = df['pb_ratio']
        
        return factors
    
    def calculate_alternative_factors(self, data, market_data=None):
        """è®¡ç®—å¦ç±»å› å­"""
        factors = {}
        
        close = np.array(data['close'])
        volume = np.array(data['volume'])
        
        # å¸‚åœºå¾®è§‚ç»“æž„å› å­
        returns = np.diff(np.log(close))
        factors['skewness'] = pd.Series(returns).rolling(20).skew()
        factors['kurtosis'] = pd.Series(returns).rolling(20).kurt()
        
        # æµåŠ¨æ€§å› å­
        factors['amihud_illiquidity'] = np.abs(returns) / volume[1:]
        
        # æ³¢åŠ¨çŽ‡å› å­
        factors['realized_volatility'] = pd.Series(returns).rolling(20).std() * np.sqrt(252)
        
        # è·³è·ƒæ£€æµ‹å› å­
        factors['jump_indicator'] = self.detect_jumps(returns)
        
        # å¦‚æžœæœ‰å¸‚åœºæ•°æ®ï¼Œè®¡ç®—betaç­‰å› å­
        if market_data is not None:
            market_returns = np.diff(np.log(market_data['close']))
            factors['beta'] = self.calculate_rolling_beta(returns, market_returns)
        
        return factors
    
    def detect_jumps(self, returns, threshold=3):
        """æ£€æµ‹ä»·æ ¼è·³è·ƒ"""
        rolling_std = pd.Series(returns).rolling(20).std()
        z_scores = np.abs(returns) / rolling_std
        return (z_scores > threshold).astype(int)
    
    def calculate_rolling_beta(self, stock_returns, market_returns, window=60):
        """è®¡ç®—æ»šåŠ¨beta"""
        betas = []
        for i in range(len(stock_returns)):
            if i < window:
                betas.append(np.nan)
            else:
                stock_slice = stock_returns[i-window:i]
                market_slice = market_returns[i-window:i]
                
                if len(market_slice) > 0 and np.var(market_slice) > 0:
                    beta = np.cov(stock_slice, market_slice)[0, 1] / np.var(market_slice)
                    betas.append(beta)
                else:
                    betas.append(np.nan)
        
        return np.array(betas)
    
    def calculate_factor_scores(self, factors_dict):
        """è®¡ç®—å› å­ç»¼åˆè¯„åˆ†"""
        # å°†æ‰€æœ‰å› å­ç»„åˆæˆçŸ©é˜µ
        factor_matrix = []
        factor_names = []
        
        for name, values in factors_dict.items():
            if len(values) > 0 and not np.all(np.isnan(values)):
                factor_matrix.append(values)
                factor_names.append(name)
        
        if len(factor_matrix) == 0:
            return {}
        
        factor_matrix = np.array(factor_matrix).T
        
        # æ ‡å‡†åŒ–
        factor_matrix_scaled = self.scaler.fit_transform(factor_matrix)
        
        # PCAé™ç»´
        pca = PCA(n_components=min(5, factor_matrix_scaled.shape[1]))
        principal_components = pca.fit_transform(factor_matrix_scaled)
        
        # è®¡ç®—å› å­é‡è¦æ€§
        feature_importance = np.abs(pca.components_).mean(axis=0)
        
        return {
            'factor_names': factor_names,
            'importance_scores': feature_importance,
            'principal_components': principal_components,
            'explained_variance_ratio': pca.explained_variance_ratio_
        }

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    calculator = FactorCalculator()
    
    # æ¨¡æ‹Ÿæ•°æ®
    dates = pd.date_range('2023-01-01', periods=100, freq='D')
    data = {
        'high': np.random.randn(100).cumsum() + 100,
        'low': np.random.randn(100).cumsum() + 95,
        'close': np.random.randn(100).cumsum() + 98,
        'volume': np.random.randint(1000000, 10000000, 100)
    }
    
    # è®¡ç®—æŠ€æœ¯å› å­
    tech_factors = calculator.calculate_technical_factors(data)
    print("æŠ€æœ¯å› å­è®¡ç®—å®Œæˆï¼Œå…±", len(tech_factors), "ä¸ªå› å­")
    
    # è®¡ç®—å› å­è¯„åˆ†
    scores = calculator.calculate_factor_scores(tech_factors)
    print("å› å­é‡è¦æ€§è¯„åˆ†å®Œæˆ")
EOF
    
    chmod +x server/scripts/factor_calculator.py
    
    log_success "å› å­è®¡ç®—Pythonè„šæœ¬åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºæµ‹è¯•è„šæœ¬
create_test_scripts() {
    log_info "åˆ›å»ºç‰¹å¾å·¥ç¨‹æµ‹è¯•è„šæœ¬..."
    
    cat > scripts/test-phase2-features.sh << 'EOF'
#!/bin/bash

# ç¬¬äºŒé˜¶æ®µç‰¹å¾å·¥ç¨‹æµ‹è¯•è„šæœ¬

set -e

echo "ðŸ§ª æµ‹è¯•ç¬¬äºŒé˜¶æ®µç‰¹å¾å·¥ç¨‹åŠŸèƒ½"

# æµ‹è¯•å› å­è®¡ç®—API
echo "æµ‹è¯•å› å­è®¡ç®—API..."
curl -s -X POST http://localhost:7001/api/factor/calculate \
  -H "Content-Type: application/json" \
  -d '{"symbol":"000001","factorTypes":["technical"]}' | jq .

# æµ‹è¯•å› å­é…ç½®API
echo "æµ‹è¯•å› å­é…ç½®API..."
curl -s http://localhost:7001/api/factor/configs | jq .

# æµ‹è¯•å› å­ç›¸å…³æ€§API
echo "æµ‹è¯•å› å­ç›¸å…³æ€§API..."
curl -s "http://localhost:7001/api/factor/correlation?symbol=000001" | jq .

# æµ‹è¯•å› å­é‡è¦æ€§API
echo "æµ‹è¯•å› å­é‡è¦æ€§API..."
curl -s "http://localhost:7001/api/factor/importance?symbol=000001" | jq .

echo "âœ… ç¬¬äºŒé˜¶æ®µåŠŸèƒ½æµ‹è¯•å®Œæˆ"
EOF
    
    chmod +x scripts/test-phase2-features.sh
    
    log_success "æµ‹è¯•è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# æ›´æ–°é…ç½®æ–‡ä»¶
update_configurations() {
    log_info "æ›´æ–°é…ç½®æ–‡ä»¶..."
    
    # æ›´æ–°package.jsonè„šæœ¬
    if [ -f "package.json" ]; then
        # æ·»åŠ å› å­è®¡ç®—ç›¸å…³è„šæœ¬
        npm pkg set scripts.factor:calculate="node server/scripts/factor_calculator.js"
        npm pkg set scripts.factor:test="./scripts/test-phase2-features.sh"
    fi
    
    log_success "é…ç½®æ–‡ä»¶æ›´æ–°å®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    echo "ðŸš€ é‡åŒ–äº¤æ˜“ç³»ç»Ÿç¬¬äºŒé˜¶æ®µï¼šç‰¹å¾å·¥ç¨‹æ¨¡å—å®‰è£…"
    echo "ðŸ“‹ æœ¬é˜¶æ®µå°†å®‰è£…ä»¥ä¸‹ç»„ä»¶ï¼š"
    echo "   - æŠ€æœ¯æŒ‡æ ‡å› å­å¼•æ“Ž"
    echo "   - åŸºæœ¬é¢å› å­å¼•æ“Ž"
    echo "   - å¦ç±»å› å­å¼•æ“Ž"
    echo "   - å› å­åˆ†æžå’Œå¯è§†åŒ–"
    echo "   - é«˜æ€§èƒ½å› å­è®¡ç®—"
    echo ""
    
    read -p "æ˜¯å¦ç»§ç»­å®‰è£…ç¬¬äºŒé˜¶æ®µï¼Ÿ(y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "å®‰è£…å·²å–æ¶ˆ"
        exit 0
    fi
    
    # æ£€æŸ¥æ˜¯å¦åœ¨é¡¹ç›®æ ¹ç›®å½•
    if [ ! -f "package.json" ] || [ ! -d "server" ]; then
        log_error "è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬"
        exit 1
    fi
    
    check_phase1_completion
    install_frontend_dependencies
    install_backend_dependencies
    install_python_libraries
    create_factor_tables
    setup_clickhouse_factor_tables
    create_factor_calculation_scripts
    create_test_scripts
    update_configurations
    
    log_success "ðŸŽ‰ ç¬¬äºŒé˜¶æ®µç‰¹å¾å·¥ç¨‹æ¨¡å—å®‰è£…å®Œæˆï¼"
    echo ""
    log_info "ä¸‹ä¸€æ­¥ï¼š"
    log_info "1. é‡å¯æœåŠ¡: ./scripts/start-services.sh"
    log_info "2. æµ‹è¯•åŠŸèƒ½: ./scripts/test-phase2-features.sh"
    log_info "3. è®¿é—®å› å­åˆ†æžé¡µé¢æŸ¥çœ‹æ–°åŠŸèƒ½"
    echo ""
    
    read -p "æ˜¯å¦ç«‹å³é‡å¯æœåŠ¡ï¼Ÿ(y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        ./scripts/stop-services.sh
        sleep 2
        ./scripts/start-services.sh
    fi
}

# è¿è¡Œä¸»å‡½æ•°
main "$@"
EOF
