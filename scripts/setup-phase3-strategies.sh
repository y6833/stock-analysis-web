#!/bin/bash

# ç¬¬ä¸‰é˜¶æ®µï¼šç­–ç•¥æ¨¡å—å‡çº§å®‰è£…è„šæœ¬
# æž„å»ºä¸“ä¸šçš„é‡åŒ–ç­–ç•¥å¼€å‘å¹³å°

echo "ðŸš€ å¼€å§‹ç¬¬ä¸‰é˜¶æ®µï¼šç­–ç•¥æ¨¡å—å‡çº§..."

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    log_info "æ£€æŸ¥ç³»ç»Ÿä¾èµ–..."
    
    # æ£€æŸ¥Node.js
    if ! command -v node &> /dev/null; then
        log_error "Node.js æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Node.js"
        exit 1
    fi
    
    # æ£€æŸ¥npm
    if ! command -v npm &> /dev/null; then
        log_error "npm æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… npm"
        exit 1
    fi
    
    # æ£€æŸ¥Pythonï¼ˆç”¨äºŽæœºå™¨å­¦ä¹ æ¨¡å—ï¼‰
    if ! command -v python &> /dev/null && ! command -v python3 &> /dev/null; then
        log_warning "Python æœªå®‰è£…ï¼Œæœºå™¨å­¦ä¹ åŠŸèƒ½å¯èƒ½å—é™"
    fi
    
    log_success "ä¾èµ–æ£€æŸ¥å®Œæˆ"
}

# å®‰è£…å‰ç«¯ä¾èµ–
install_frontend_deps() {
    log_info "å®‰è£…å‰ç«¯ç­–ç•¥æ¨¡å—ä¾èµ–..."
    
    # å®‰è£…æœºå™¨å­¦ä¹ ç›¸å…³åº“
    npm install --save \
        ml-matrix \
        ml-regression \
        ml-kmeans \
        simple-statistics \
        d3-array \
        lodash-es
    
    # å®‰è£…å›¾è¡¨åº“
    npm install --save \
        echarts \
        @types/echarts
    
    # å®‰è£…æ•°å­¦è®¡ç®—åº“
    npm install --save \
        mathjs \
        numeric \
        @types/numeric
    
    log_success "å‰ç«¯ä¾èµ–å®‰è£…å®Œæˆ"
}

# å®‰è£…åŽç«¯ä¾èµ–
install_backend_deps() {
    log_info "å®‰è£…åŽç«¯ç­–ç•¥æ¨¡å—ä¾èµ–..."
    
    cd server
    
    # å®‰è£…æ•°æ®ç§‘å­¦ç›¸å…³åº“
    npm install --save \
        mathjs \
        simple-statistics \
        ml-matrix \
        node-cron \
        uuid
    
    # å®‰è£…Pythonä¾èµ–ï¼ˆå¦‚æžœPythonå¯ç”¨ï¼‰
    if command -v python3 &> /dev/null; then
        log_info "å®‰è£…Pythonæœºå™¨å­¦ä¹ ä¾èµ–..."
        python3 -m pip install --user \
            numpy \
            pandas \
            scikit-learn \
            xgboost \
            lightgbm \
            matplotlib \
            seaborn \
            joblib
    elif command -v python &> /dev/null; then
        log_info "å®‰è£…Pythonæœºå™¨å­¦ä¹ ä¾èµ–..."
        python -m pip install --user \
            numpy \
            pandas \
            scikit-learn \
            xgboost \
            lightgbm \
            matplotlib \
            seaborn \
            joblib
    fi
    
    cd ..
    log_success "åŽç«¯ä¾èµ–å®‰è£…å®Œæˆ"
}

# åˆ›å»ºæ•°æ®åº“è¡¨
create_database_tables() {
    log_info "åˆ›å»ºç­–ç•¥ç›¸å…³æ•°æ®åº“è¡¨..."
    
    # åˆ›å»ºç­–ç•¥è¡¨
    cat > server/database/create_strategy_tables.sql << 'EOF'
-- ç­–ç•¥è¡¨
CREATE TABLE IF NOT EXISTS strategies (
  id VARCHAR(50) PRIMARY KEY,
  user_id INT NOT NULL,
  name VARCHAR(100) NOT NULL,
  type ENUM('factor', 'ml', 'timing', 'portfolio', 'arbitrage', 'custom') NOT NULL,
  description TEXT,
  parameters JSON,
  enabled BOOLEAN DEFAULT TRUE,
  priority INT DEFAULT 0,
  risk_level ENUM('low', 'medium', 'high') DEFAULT 'medium',
  expected_return DECIMAL(8,4) DEFAULT 0.0000,
  max_drawdown DECIMAL(8,4) DEFAULT 0.0000,
  rebalance_frequency ENUM('daily', 'weekly', 'monthly', 'quarterly') DEFAULT 'weekly',
  universe JSON,
  benchmark VARCHAR(20) DEFAULT '000300.SH',
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  INDEX idx_user_id (user_id),
  INDEX idx_type (type),
  INDEX idx_enabled (enabled)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ç­–ç•¥æ‰§è¡ŒåŽ†å²è¡¨
CREATE TABLE IF NOT EXISTS strategy_executions (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  strategy_id VARCHAR(50) NOT NULL,
  execution_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  signals JSON,
  positions JSON,
  performance JSON,
  risk_metrics JSON,
  metadata JSON,
  status ENUM('success', 'failed', 'partial') DEFAULT 'success',
  error_message TEXT,
  execution_duration INT DEFAULT 0,
  INDEX idx_strategy_id (strategy_id),
  INDEX idx_execution_time (execution_time),
  FOREIGN KEY (strategy_id) REFERENCES strategies(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ç­–ç•¥ä¼˜åŒ–åŽ†å²è¡¨
CREATE TABLE IF NOT EXISTS strategy_optimizations (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  strategy_id VARCHAR(50) NOT NULL,
  optimization_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  original_parameters JSON,
  optimized_parameters JSON,
  optimization_config JSON,
  objective_value DECIMAL(10,6),
  iterations INT DEFAULT 0,
  convergence BOOLEAN DEFAULT FALSE,
  improvement DECIMAL(8,4) DEFAULT 0.0000,
  INDEX idx_strategy_id (strategy_id),
  INDEX idx_optimization_time (optimization_time),
  FOREIGN KEY (strategy_id) REFERENCES strategies(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ç­–ç•¥ä¿¡å·è¡¨
CREATE TABLE IF NOT EXISTS strategy_signals (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  strategy_id VARCHAR(50) NOT NULL,
  execution_id BIGINT,
  symbol VARCHAR(20) NOT NULL,
  action ENUM('buy', 'sell', 'hold') NOT NULL,
  strength DECIMAL(5,4) DEFAULT 0.0000,
  confidence DECIMAL(5,4) DEFAULT 0.0000,
  price DECIMAL(10,3) NOT NULL,
  quantity INT NOT NULL,
  reason TEXT,
  signal_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  INDEX idx_strategy_id (strategy_id),
  INDEX idx_symbol (symbol),
  INDEX idx_signal_time (signal_time),
  FOREIGN KEY (strategy_id) REFERENCES strategies(id) ON DELETE CASCADE,
  FOREIGN KEY (execution_id) REFERENCES strategy_executions(id) ON DELETE SET NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ç­–ç•¥æŒä»“è¡¨
CREATE TABLE IF NOT EXISTS strategy_positions (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  strategy_id VARCHAR(50) NOT NULL,
  symbol VARCHAR(20) NOT NULL,
  quantity INT NOT NULL,
  avg_price DECIMAL(10,3) NOT NULL,
  current_price DECIMAL(10,3) NOT NULL,
  market_value DECIMAL(15,2) NOT NULL,
  unrealized_pnl DECIMAL(15,2) DEFAULT 0.00,
  weight DECIMAL(5,4) DEFAULT 0.0000,
  holding_period INT DEFAULT 0,
  last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  INDEX idx_strategy_id (strategy_id),
  INDEX idx_symbol (symbol),
  UNIQUE KEY uk_strategy_symbol (strategy_id, symbol),
  FOREIGN KEY (strategy_id) REFERENCES strategies(id) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
EOF

    # æ‰§è¡ŒSQL
    if command -v mysql &> /dev/null; then
        mysql -u root -proot stock_analysis < server/database/create_strategy_tables.sql
        log_success "ç­–ç•¥æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ"
    else
        log_warning "MySQLæœªæ‰¾åˆ°ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ server/database/create_strategy_tables.sql"
    fi
}

# åˆ›å»ºPythonæœºå™¨å­¦ä¹ æœåŠ¡
create_ml_service() {
    log_info "åˆ›å»ºPythonæœºå™¨å­¦ä¹ æœåŠ¡..."
    
    mkdir -p server/ml_service
    
    cat > server/ml_service/ml_engine.py << 'EOF'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœºå™¨å­¦ä¹ å¼•æ“Ž
æä¾›ç­–ç•¥æ‰€éœ€çš„æœºå™¨å­¦ä¹ åŠŸèƒ½
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import xgboost as xgb
import lightgbm as lgb
import joblib
import json
import sys
import os
from datetime import datetime

class MLEngine:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_names = {}
        
    def train_model(self, model_type, features, labels, model_params=None):
        """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡åž‹"""
        try:
            # æ•°æ®é¢„å¤„ç†
            X = np.array(features)
            y = np.array(labels)
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42
            )
            
            # é€‰æ‹©æ¨¡åž‹
            if model_type == 'xgboost':
                model = xgb.XGBClassifier(**(model_params or {}))
            elif model_type == 'lightgbm':
                model = lgb.LGBMClassifier(**(model_params or {}))
            elif model_type == 'random_forest':
                model = RandomForestClassifier(**(model_params or {}))
            elif model_type == 'gradient_boosting':
                model = GradientBoostingClassifier(**(model_params or {}))
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡åž‹ç±»åž‹: {model_type}")
            
            # è®­ç»ƒæ¨¡åž‹
            model.fit(X_train, y_train)
            
            # é¢„æµ‹å’Œè¯„ä¼°
            y_pred = model.predict(X_test)
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            performance = {
                'accuracy': accuracy_score(y_test, y_pred),
                'precision': precision_score(y_test, y_pred, average='weighted'),
                'recall': recall_score(y_test, y_pred, average='weighted'),
                'f1_score': f1_score(y_test, y_pred, average='weighted')
            }
            
            # äº¤å‰éªŒè¯
            cv_scores = cross_val_score(model, X_scaled, y, cv=5)
            performance['cv_mean'] = cv_scores.mean()
            performance['cv_std'] = cv_scores.std()
            
            return {
                'success': True,
                'model': model,
                'scaler': scaler,
                'performance': performance,
                'feature_importance': model.feature_importances_.tolist() if hasattr(model, 'feature_importances_') else None
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def predict(self, model_id, features):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹è¿›è¡Œé¢„æµ‹"""
        try:
            if model_id not in self.models:
                return {'success': False, 'error': 'æ¨¡åž‹ä¸å­˜åœ¨'}
            
            model = self.models[model_id]
            scaler = self.scalers[model_id]
            
            # ç‰¹å¾æ ‡å‡†åŒ–
            X = np.array(features).reshape(1, -1)
            X_scaled = scaler.transform(X)
            
            # é¢„æµ‹
            prediction = model.predict(X_scaled)[0]
            probability = model.predict_proba(X_scaled)[0] if hasattr(model, 'predict_proba') else [0.5, 0.5]
            
            return {
                'success': True,
                'prediction': int(prediction),
                'probability': probability.tolist(),
                'confidence': max(probability)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def save_model(self, model_id, model, scaler, feature_names=None):
        """ä¿å­˜æ¨¡åž‹"""
        try:
            model_dir = f'models/{model_id}'
            os.makedirs(model_dir, exist_ok=True)
            
            # ä¿å­˜æ¨¡åž‹å’Œæ ‡å‡†åŒ–å™¨
            joblib.dump(model, f'{model_dir}/model.pkl')
            joblib.dump(scaler, f'{model_dir}/scaler.pkl')
            
            # ä¿å­˜ç‰¹å¾åç§°
            if feature_names:
                with open(f'{model_dir}/features.json', 'w') as f:
                    json.dump(feature_names, f)
            
            # æ›´æ–°å†…å­˜ä¸­çš„æ¨¡åž‹
            self.models[model_id] = model
            self.scalers[model_id] = scaler
            if feature_names:
                self.feature_names[model_id] = feature_names
            
            return {'success': True}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def load_model(self, model_id):
        """åŠ è½½æ¨¡åž‹"""
        try:
            model_dir = f'models/{model_id}'
            
            # åŠ è½½æ¨¡åž‹å’Œæ ‡å‡†åŒ–å™¨
            model = joblib.load(f'{model_dir}/model.pkl')
            scaler = joblib.load(f'{model_dir}/scaler.pkl')
            
            # åŠ è½½ç‰¹å¾åç§°
            feature_names = None
            if os.path.exists(f'{model_dir}/features.json'):
                with open(f'{model_dir}/features.json', 'r') as f:
                    feature_names = json.load(f)
            
            # æ›´æ–°å†…å­˜ä¸­çš„æ¨¡åž‹
            self.models[model_id] = model
            self.scalers[model_id] = scaler
            if feature_names:
                self.feature_names[model_id] = feature_names
            
            return {'success': True}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}

def main():
    """å‘½ä»¤è¡ŒæŽ¥å£"""
    if len(sys.argv) < 2:
        print(json.dumps({'success': False, 'error': 'ç¼ºå°‘å‘½ä»¤å‚æ•°'}))
        return
    
    command = sys.argv[1]
    engine = MLEngine()
    
    if command == 'train':
        # è®­ç»ƒæ¨¡åž‹
        data = json.loads(sys.argv[2])
        result = engine.train_model(
            data['model_type'],
            data['features'],
            data['labels'],
            data.get('model_params')
        )
        print(json.dumps(result, default=str))
        
    elif command == 'predict':
        # é¢„æµ‹
        data = json.loads(sys.argv[2])
        engine.load_model(data['model_id'])
        result = engine.predict(data['model_id'], data['features'])
        print(json.dumps(result))
        
    else:
        print(json.dumps({'success': False, 'error': f'æœªçŸ¥å‘½ä»¤: {command}'}))

if __name__ == '__main__':
    main()
EOF

    chmod +x server/ml_service/ml_engine.py
    log_success "Pythonæœºå™¨å­¦ä¹ æœåŠ¡åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºé…ç½®æ–‡ä»¶
create_config_files() {
    log_info "åˆ›å»ºç­–ç•¥é…ç½®æ–‡ä»¶..."
    
    # åˆ›å»ºç­–ç•¥é…ç½®
    cat > src/config/strategy.config.ts << 'EOF'
/**
 * ç­–ç•¥é…ç½®æ–‡ä»¶
 */

export const STRATEGY_CONFIG = {
  // ç­–ç•¥ç±»åž‹é…ç½®
  STRATEGY_TYPES: {
    factor: {
      name: 'å› å­ç­–ç•¥',
      description: 'åŸºäºŽé‡åŒ–å› å­çš„é€‰è‚¡ç­–ç•¥',
      icon: 'factor',
      color: '#409EFF'
    },
    ml: {
      name: 'æœºå™¨å­¦ä¹ ç­–ç•¥',
      description: 'åŸºäºŽæœºå™¨å­¦ä¹ æ¨¡åž‹çš„é€‰è‚¡ç­–ç•¥',
      icon: 'ml',
      color: '#67C23A'
    },
    timing: {
      name: 'æ‹©æ—¶ç­–ç•¥',
      description: 'åŸºäºŽæŠ€æœ¯æŒ‡æ ‡çš„æ‹©æ—¶ç­–ç•¥',
      icon: 'timing',
      color: '#E6A23C'
    },
    portfolio: {
      name: 'ç»„åˆç­–ç•¥',
      description: 'å¤šç­–ç•¥ç»„åˆä¼˜åŒ–',
      icon: 'portfolio',
      color: '#F56C6C'
    }
  },

  // é£Žé™©ç­‰çº§é…ç½®
  RISK_LEVELS: {
    low: {
      name: 'ä½Žé£Žé™©',
      color: '#67C23A',
      maxDrawdown: 0.1,
      volatility: 0.15
    },
    medium: {
      name: 'ä¸­é£Žé™©',
      color: '#E6A23C',
      maxDrawdown: 0.2,
      volatility: 0.25
    },
    high: {
      name: 'é«˜é£Žé™©',
      color: '#F56C6C',
      maxDrawdown: 0.3,
      volatility: 0.35
    }
  },

  // é»˜è®¤å‚æ•°
  DEFAULT_PARAMS: {
    factor: {
      lookbackPeriod: 20,
      rebalancePeriod: 5,
      topN: 10,
      factorWeights: []
    },
    ml: {
      modelType: 'xgboost',
      maxFeatures: 10,
      trainPeriod: 60,
      retrainPeriod: 30,
      threshold: 0.02
    },
    timing: {
      indicators: ['sma', 'rsi', 'macd'],
      period: 20,
      threshold: 0.7
    },
    portfolio: {
      maxPositions: 10,
      rebalanceFrequency: 'weekly',
      riskBudget: 0.15
    }
  }
}

export default STRATEGY_CONFIG
EOF

    log_success "ç­–ç•¥é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# ä¸»å‡½æ•°
main() {
    echo "ðŸš€ ç¬¬ä¸‰é˜¶æ®µï¼šç­–ç•¥æ¨¡å—å‡çº§"
    echo "================================"
    
    check_dependencies
    install_frontend_deps
    install_backend_deps
    create_database_tables
    create_ml_service
    create_config_files
    
    echo ""
    echo "================================"
    log_success "ç¬¬ä¸‰é˜¶æ®µç­–ç•¥æ¨¡å—å‡çº§å®Œæˆï¼"
    echo ""
    echo "ðŸ“‹ å®Œæˆçš„åŠŸèƒ½ï¼š"
    echo "  âœ… ç­–ç•¥æ¡†æž¶æ ¸å¿ƒæž¶æž„"
    echo "  âœ… æœºå™¨å­¦ä¹ ç­–ç•¥å¼•æ“Ž"
    echo "  âœ… å¤šå› å­é€‰è‚¡æ¨¡åž‹"
    echo "  âœ… æ‹©æ—¶ç­–ç•¥å¼•æ“Ž"
    echo "  âœ… ç»„åˆä¼˜åŒ–å™¨"
    echo "  âœ… ç­–ç•¥è¯„ä¼°ä¸Žå¯è§†åŒ–"
    echo "  âœ… Pythonæœºå™¨å­¦ä¹ æœåŠ¡"
    echo "  âœ… æ•°æ®åº“è¡¨ç»“æž„"
    echo ""
    echo "ðŸ”§ ä¸‹ä¸€æ­¥ï¼š"
    echo "  1. é‡å¯å‰ç«¯å’ŒåŽç«¯æœåŠ¡"
    echo "  2. è®¿é—®ç­–ç•¥ç®¡ç†é¡µé¢æµ‹è¯•åŠŸèƒ½"
    echo "  3. åˆ›å»ºå’Œè¿è¡Œç¬¬ä¸€ä¸ªç­–ç•¥"
    echo ""
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
